{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64_el0B8ipKX"
      },
      "source": [
        "### Script translation text(en) to malagasy(mg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xLJGJcatiVv7"
      },
      "outputs": [],
      "source": [
        "!pip install -U bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OL1znWQHbWTD"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import pandas as pd\n",
        "import torch\n",
        "from google.colab import drive\n",
        "from tqdm.auto import tqdm\n",
        "import wandb\n",
        "import argparse\n",
        "\n",
        "import subprocess\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "SsSw60x4WMOl"
      },
      "outputs": [],
      "source": [
        "# Définir les arguments pour le script\n",
        "parser = argparse.ArgumentParser(description='Translate a portion of a CSV file using MADLAD-400-7B-MT-BT.')\n",
        "parser.add_argument('--start_index', type=int, default=0, help='Index de la première ligne à traiter (inclusive).')\n",
        "parser.add_argument('--end_index', type=int, default=10000, help='Index de la dernière ligne à traiter (exclusive).')\n",
        "parser.add_argument('--batch_size', type=int, default=16, help='Taille du lot pour la traduction.')\n",
        "args = parser.parse_args()\n",
        "\n",
        "start_index = args.start_index\n",
        "end_index = args.end_index\n",
        "batch_size = args.batch_size\n",
        "\n",
        "# Vérifier si un GPU est disponible et le définir comme device, sinon utiliser le CPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Utilisation de l'appareil : {device}\")\n",
        "\n",
        "# modèle MADLAD-400-7B-MT-BT avec quantification 8 bits\n",
        "model_name = \"google/madlad400-7b-mt-bt\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, load_in_8bit=True, device_map='auto')\n",
        "\n",
        "file_path = '/content/drive/MyDrive/hate_speech/data_combined.csv'\n",
        "try:\n",
        "    df = pd.read_csv(file_path)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Erreur: Le fichier '{file_path}' n'a pas été trouvé.\")\n",
        "    exit()\n",
        "\n",
        "# Vérifier que la colonne 'text' existe\n",
        "if 'text' not in df.columns:\n",
        "    print(\"Erreur: La colonne 'text' n'existe pas dans le fichier CSV.\")\n",
        "    exit()\n",
        "\n",
        "# Sélectionner la portion du DataFrame à traiter\n",
        "df_subset = df[start_index:end_index]\n",
        "print(f\"Traitement des lignes de {start_index} à {end_index - 1} par lots de {batch_size}.\")\n",
        "\n",
        "def translate_batch(texts):\n",
        "    input_texts = [f\"<2mg> {text}\" for text in texts]  # Ajouter le préfixe de langue: 2mg\n",
        "    inputs = tokenizer(input_texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        generated_tokens = model.generate(\n",
        "            **inputs,\n",
        "            max_length=512\n",
        "        )\n",
        "    translated_texts = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "    return translated_texts\n",
        "\n",
        "translations = [''] * len(df_subset)  # Pré-allouer la liste des traductions\n",
        "\n",
        "# Appliquer la traduction par lots avec une barre de progression\n",
        "for i in tqdm(range(0, len(df_subset), batch_size), desc=\"Traduction par lots\"):\n",
        "    batch = df_subset['text'][i:i + batch_size].tolist()\n",
        "    translated_batch = translate_batch(batch)\n",
        "    translations[i:i + batch_size] = translated_batch\n",
        "\n",
        "# Ajouter la liste des traductions comme une nouvelle colonne au sous-ensemble\n",
        "df_subset['translated'] = translations\n",
        "\n",
        "# Initialiser WandB\n",
        "wandb.init(project=\"hate-speech-translated-malagasy\")\n",
        "# Créer un tableau WandB à partir du sous-ensemble traduit (contenant 'text', 'label' et 'translated')\n",
        "wandb_table = wandb.Table(data=df_subset[['text', 'label', 'translated']], columns=[\"text\", \"label\", \"translated\"])\n",
        "\n",
        "# Enregistrer le tableau dans WandB\n",
        "wandb.log({\"translations\": wandb_table})\n",
        "\n",
        "# Fermer la run WandB\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ys_fw3MSksRu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eS1gYX8qQKo8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3bcvY7lQLG6",
        "outputId": "30572d75-a18f-4cc7-f71a-7dfdc26f6a64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Process is interrupted.\n"
          ]
        }
      ],
      "source": [
        "# %%bash\n",
        "# #!/bin/bash\n",
        "\n",
        "# echo \"Début de l'exécution des traductions...\"\n",
        "\n",
        "# # Exemple pour traiter les lignes 0 à 999 avec un batch size de 8\n",
        "# python run_translation.py --start_index 0 --end_index 1000 --batch_size 8 &\n",
        "\n",
        "# # Exemple pour traiter les lignes 1000 à 1999 avec un batch size de 8\n",
        "# python run_translation.py --start_index 1000 --end_index 2000 --batch_size 8 &\n",
        "\n",
        "# wait # Attend que tous les processus en arrière-plan se terminent\n",
        "# echo \"Toutes les tâches de traduction sont terminées.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9CP6StUQPnp"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
